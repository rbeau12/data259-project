{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d3b95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from deepface import DeepFace\n",
    "import face_recognition\n",
    "\n",
    "FAIRFACE_CSV = \"C:\\\\Users\\\\jonat\\\\Desktop\\\\dataethicsproj\\\\data259-project\\\\analysis\\\\data\\\\fairface_label_train.csv\"\n",
    "FAIRFACE_DIR = \"C:\\\\Users\\\\jonat\\\\Desktop\\\\dataethicsproj\\\\data259-project\\\\analysis\\\\data\\\\fairface-img-margin025-trainval\"\n",
    "\n",
    "# Step 1: Load and prepare the FairFace dataset\n",
    "def load_fairface_data(csv_path, image_dir, sample_size=500):\n",
    "    \"\"\"\n",
    "    Load the FairFace dataset and create intersectional categories\n",
    "    \"\"\"\n",
    "    # Load CSV with labels\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Columns in CSV file: {df.columns.tolist()}\")\n",
    "    print(f\"Total records in CSV: {len(df)}\")\n",
    "    \n",
    "    # Create intersectional categories\n",
    "    df['gender_race'] = df['gender'] + '_' + df['race']\n",
    "    print(\"Created 'gender_race' column by combining 'gender' and 'race'\")\n",
    "    \n",
    "    # Take a sample for faster processing if needed\n",
    "    if sample_size and sample_size < len(df):\n",
    "        df = df.sample(sample_size, random_state=42)\n",
    "        print(f\"Sampled {sample_size} records\")\n",
    "    \n",
    "    # Check if files exist - with more detailed debugging\n",
    "    print(f\"Checking image paths in directory: {image_dir}\")\n",
    "    # Check if directory exists\n",
    "    if not os.path.isdir(image_dir):\n",
    "        print(f\"ERROR: Image directory does not exist: {image_dir}\")\n",
    "        return df.head(0)  # Return empty dataframe\n",
    "    \n",
    "    valid_files = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking image files\"):\n",
    "        file_path = os.path.join(image_dir, row['file'])\n",
    "        if os.path.exists(file_path):\n",
    "            valid_files.append(idx)\n",
    "        else:\n",
    "            # Print a few examples of missing files for debugging\n",
    "            if len(valid_files) == 0 and len(valid_files) + len([i for i in range(len(df)) if i not in valid_files]) < 5:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "    \n",
    "    # Handle case where no files were found\n",
    "    if len(valid_files) == 0:\n",
    "        print(\"ERROR: No valid image files found!\")\n",
    "        print(\"Checking first few file paths from CSV:\")\n",
    "        for i, row in df.iloc[:5].iterrows():\n",
    "            file_path = os.path.join(image_dir, row['file'])\n",
    "            print(f\"- {file_path} (exists: {os.path.exists(file_path)})\")\n",
    "        return df.head(0)  # Return empty dataframe\n",
    "    \n",
    "    df_valid = df.loc[valid_files]\n",
    "    print(f\"Loaded {len(df_valid)} images with valid file paths out of {len(df)} total\")\n",
    "    \n",
    "    return df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "796dbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r\"C:\\Users\\jonat\\Desktop\\dataethicsproj\\data259-project\\analysis\\data\\fairface-img-margin025-trainval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5999769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_opencv_haar(data_df, sample_size=None):\n",
    "    \"\"\"\n",
    "    Analyze OpenCV Haar Cascades face detection across racial groups.\n",
    "    Args:\n",
    "        data_df: DataFrame with image paths and race labels\n",
    "        sample_size: Number of images to sample (for faster testing)\n",
    "    Returns:\n",
    "        DataFrame with detection results\n",
    "    \"\"\"\n",
    "    print(\"Analyzing OpenCV Haar Cascades...\")\n",
    "    \n",
    "    # Sample data if requested\n",
    "    if sample_size and sample_size < len(data_df):\n",
    "        data_df = data_df.sample(sample_size, random_state=42)\n",
    "    \n",
    "    # Load the pre-trained model\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in tqdm(data_df.iterrows(), total=len(data_df)):\n",
    "        img_path = os.path.join(BASE_DIR, row['file'])\n",
    "        race = row['race']\n",
    "        \n",
    "        try:\n",
    "            # Read image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                results.append({\n",
    "                    'image_path': img_path,\n",
    "                    'race': race,\n",
    "                    'detected': False,\n",
    "                    'confidence': 0,\n",
    "                    'error': 'Image could not be loaded'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Detect faces with confidence scores\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, \n",
    "                                                 minNeighbors=5, minSize=(30, 30),\n",
    "                                                 flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            \n",
    "            # Check if any faces were detected\n",
    "            if len(faces) > 0:\n",
    "                # OpenCV doesn't provide confidence scores directly, so we'll use\n",
    "                # the number of neighbors as a proxy for confidence\n",
    "                max_neighbors = 0\n",
    "                for (x, y, w, h) in faces:\n",
    "                    # Detect with different minNeighbors to get a \"confidence\" score\n",
    "                    for neighbors in range(1, 10):\n",
    "                        test_faces = face_cascade.detectMultiScale(\n",
    "                            gray[y:y+h, x:x+w], \n",
    "                            scaleFactor=1.1, \n",
    "                            minNeighbors=neighbors\n",
    "                        )\n",
    "                        if len(test_faces) > 0:\n",
    "                            max_neighbors = max(max_neighbors, neighbors)\n",
    "                \n",
    "                results.append({\n",
    "                    'image_path': img_path,\n",
    "                    'race': race,\n",
    "                    'detected': True,\n",
    "                    'confidence': max_neighbors / 10.0,  # Normalize to 0-1 range\n",
    "                    'faces_count': len(faces),\n",
    "                    'error': None\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    'image_path': img_path,\n",
    "                    'race': race,\n",
    "                    'detected': False,\n",
    "                    'confidence': 0,\n",
    "                    'faces_count': 0,\n",
    "                    'error': None\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'image_path': img_path,\n",
    "                'race': race,\n",
    "                'detected': False,\n",
    "                'confidence': 0,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e0d65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_deepface(df, image_dir):\n",
    "    \"\"\"\n",
    "    Test DeepFace for face detection and demographic classification\n",
    "    \"\"\"\n",
    "    # Handle empty dataframe\n",
    "    if len(df) == 0:\n",
    "        print(\"No images to process for DeepFace\")\n",
    "        return pd.DataFrame(columns=['file', 'gender', 'race', 'age', 'gender_race', 'detected', \n",
    "                                    'predicted_gender', 'predicted_race', 'predicted_age', \n",
    "                                    'gender_correct', 'race_correct'])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Testing DeepFace\"):\n",
    "        # Use the corrected path if available\n",
    "        if 'corrected_path' in row:\n",
    "            img_path = row['corrected_path']\n",
    "        else:\n",
    "            img_path = os.path.join(image_dir, row['file'])\n",
    "        \n",
    "        try:\n",
    "            # Analyze image with DeepFace\n",
    "            analysis = DeepFace.analyze(\n",
    "                img_path=img_path, \n",
    "                actions=['age', 'gender', 'race'], \n",
    "                enforce_detection=False\n",
    "            )\n",
    "            \n",
    "            # Handle single face or multiple faces\n",
    "            if isinstance(analysis, list):\n",
    "                analysis = analysis[0]  # Take first face if multiple\n",
    "            \n",
    "            # Debug output for first few results to understand structure\n",
    "            if len(results) < 2:\n",
    "                print(f\"DeepFace analysis structure for {row['file']}:\")\n",
    "                print(type(analysis))\n",
    "                print(analysis.keys() if isinstance(analysis, dict) else \"Not a dict\")\n",
    "                if isinstance(analysis, dict):\n",
    "                    for k, v in analysis.items():\n",
    "                        print(f\"  {k}: {type(v)} - {v}\")\n",
    "            \n",
    "            # Initialize result dict with metadata\n",
    "            result = {\n",
    "                'file': row['file'],\n",
    "                'gender': row['gender'],\n",
    "                'race': row['race'],\n",
    "                'age': row['age'],\n",
    "                'gender_race': row['gender_race'],\n",
    "                'detected': True,\n",
    "                'predicted_gender': None,\n",
    "                'predicted_race': None,\n",
    "                'predicted_age': None,\n",
    "                'gender_correct': False,\n",
    "                'race_correct': False\n",
    "            }\n",
    "            \n",
    "            # Safely extract predictions\n",
    "            if isinstance(analysis, dict):\n",
    "                # Gender - handle different possible structures\n",
    "                if 'gender' in analysis:\n",
    "                    if isinstance(analysis['gender'], str):\n",
    "                        result['predicted_gender'] = analysis['gender']\n",
    "                    elif isinstance(analysis['gender'], dict) and 'dominant_gender' in analysis['gender']:\n",
    "                        result['predicted_gender'] = analysis['gender']['dominant_gender']\n",
    "                \n",
    "                # Race - handle different possible structures\n",
    "                if 'race' in analysis:\n",
    "                    if isinstance(analysis['race'], str):\n",
    "                        result['predicted_race'] = analysis['race']\n",
    "                    elif isinstance(analysis['race'], dict) and 'dominant_race' in analysis['race']:\n",
    "                        result['predicted_race'] = analysis['race']['dominant_race']\n",
    "                    elif 'dominant_race' in analysis:\n",
    "                        result['predicted_race'] = analysis['dominant_race']\n",
    "                \n",
    "                # Age - handle different possible structures\n",
    "                if 'age' in analysis:\n",
    "                    if isinstance(analysis['age'], (int, float, str)):\n",
    "                        result['predicted_age'] = float(analysis['age'])\n",
    "                    elif isinstance(analysis['age'], dict) and 'apparent_age' in analysis['age']:\n",
    "                        result['predicted_age'] = float(analysis['age']['apparent_age'])\n",
    "            \n",
    "            # The correct way to extract gender prediction\n",
    "            if 'dominant_gender' in analysis:\n",
    "                result['predicted_gender'] = analysis['dominant_gender']\n",
    "            elif 'gender' in analysis and isinstance(analysis['gender'], dict):\n",
    "                # Get the gender with highest confidence\n",
    "                result['predicted_gender'] = max(analysis['gender'].items(), key=lambda x: x[1])[0]\n",
    "\n",
    "            # Then compare with FairFace label\n",
    "            # Map DeepFace's \"Man\"/\"Woman\" to FairFace's \"Male\"/\"Female\"\n",
    "            gender_mapping = {\n",
    "                'man': 'male',\n",
    "                'woman': 'female'\n",
    "            }\n",
    "\n",
    "            if result['predicted_gender'] is not None:\n",
    "                predicted_gender_lower = result['predicted_gender'].lower()\n",
    "                if predicted_gender_lower in gender_mapping:\n",
    "                    predicted_gender_mapped = gender_mapping[predicted_gender_lower]\n",
    "                    result['gender_correct'] = predicted_gender_mapped == row['gender'].lower()\n",
    "            \n",
    "            # Map race categories between FairFace and DeepFace\n",
    "            race_mapping = {\n",
    "                'white': ['White'],\n",
    "                'black': ['Black'],\n",
    "                'asian': ['East Asian', 'Southeast Asian'],\n",
    "                'indian': ['Indian'],\n",
    "                'middle eastern': ['Middle Eastern'],\n",
    "                'latino hispanic': ['Latino_Hispanic']\n",
    "            }\n",
    "            \n",
    "            # Check if race prediction is correct\n",
    "            if result['predicted_race'] is not None:\n",
    "                predicted_race_lower = result['predicted_race'].lower()\n",
    "                for df_race, ff_races in race_mapping.items():\n",
    "                    if predicted_race_lower == df_race and row['race'] in ff_races:\n",
    "                        result['race_correct'] = True\n",
    "                        break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path} with DeepFace: {e}\")\n",
    "            # Handle failed analysis\n",
    "            result = {\n",
    "                'file': row['file'],\n",
    "                'gender': row['gender'],\n",
    "                'race': row['race'],\n",
    "                'age': row['age'],\n",
    "                'gender_race': row['gender_race'],\n",
    "                'detected': False,\n",
    "                'predicted_gender': None,\n",
    "                'predicted_race': None,\n",
    "                'predicted_age': None,\n",
    "                'gender_correct': False,\n",
    "                'race_correct': False\n",
    "            }\n",
    "            \n",
    "        results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"DeepFace results shape: {results_df.shape}, columns: {results_df.columns.tolist()}\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5fb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(df_results, output_dir='finalfinalresults'):\n",
    "    \"\"\"\n",
    "    Create a comprehensive set of visualizations for facial analysis models\n",
    "    \n",
    "    Args:\n",
    "        df_results: DataFrame with results (must contain predicted_gender, predicted_race, \n",
    "                   predicted_age, gender, race, age, gender_correct, race_correct columns)\n",
    "        output_dir: Directory to save visualizations (default: current directory)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set up plotting style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    sns.set_palette(\"viridis\")\n",
    "    \n",
    "    # Calculate age difference\n",
    "    # if all(col in df_results.columns for col in ['predicted_age', 'age']):\n",
    "    #     # Convert age columns to numeric if they're not already\n",
    "    #     df_results['age'] = pd.to_numeric(df_results['age'], errors='coerce')\n",
    "    #     df_results['predicted_age'] = pd.to_numeric(df_results['predicted_age'], errors='coerce')\n",
    "        \n",
    "    #     # Calculate age difference (absolute error)\n",
    "    #     df_results['age_diff'] = (df_results['predicted_age'] - df_results['age']).abs()\n",
    "        \n",
    "    #     # Create a copy with non-null age difference values\n",
    "    #     df_age = df_results.dropna(subset=['age_diff']).copy()\n",
    "        \n",
    "    #     # Print summary statistics for age prediction\n",
    "    #     print(\"\\nAge Prediction Error Statistics:\")\n",
    "    #     print(f\"Mean absolute error: {df_age['age_diff'].mean():.2f} years\")\n",
    "    #     print(f\"Median absolute error: {df_age['age_diff'].median():.2f} years\")\n",
    "    #     print(f\"Min absolute error: {df_age['age_diff'].min():.2f} years\")\n",
    "    #     print(f\"Max absolute error: {df_age['age_diff'].max():.2f} years\")\n",
    "    # else:\n",
    "    #     print(\"Age columns not found. Skipping age prediction analysis.\")\n",
    "    #     df_age = pd.DataFrame()  # Empty dataframe\n",
    "    \n",
    "    # 1. OVERALL CLASSIFICATION ACCURACY\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Calculate overall accuracy rates\n",
    "    accuracy_data = {}\n",
    "    \n",
    "    if 'gender_correct' in df_results.columns:\n",
    "        accuracy_data['Gender Classification'] = df_results['gender_correct'].mean() * 100\n",
    "    \n",
    "    if 'race_correct' in df_results.columns:\n",
    "        accuracy_data['Race Classification'] = df_results['race_correct'].mean() * 100\n",
    "    \n",
    "    if 'detected' in df_results.columns:\n",
    "        accuracy_data['Face Detection'] = df_results['detected'].mean() * 100\n",
    "    \n",
    "    if accuracy_data:\n",
    "        # Create bar chart\n",
    "        bars = ax.bar(accuracy_data.keys(), accuracy_data.values())\n",
    "        \n",
    "        # Add labels and formatting\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title('Overall Classification Accuracy')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'overall_accuracy.png'), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. GENDER CLASSIFICATION ACCURACY BY RACE\n",
    "    \n",
    "    if all(col in df_results.columns for col in ['gender_correct', 'race']):\n",
    "        gender_by_race = df_results.groupby('race')['gender_correct'].mean() * 100\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        bars = ax.bar(gender_by_race.index, gender_by_race.values)\n",
    "        \n",
    "        # Add labels and formatting\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_xlabel('Race')\n",
    "        ax.set_ylabel('Gender Classification Accuracy (%)')\n",
    "        ax.set_title('Gender Classification Accuracy by Race')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'gender_accuracy_by_race.png'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Print findings\n",
    "        print(\"\\nGender Classification Accuracy by Race:\")\n",
    "        print(gender_by_race.sort_values())\n",
    "        print(f\"Disparity: {gender_by_race.max() - gender_by_race.min():.2f}% between {gender_by_race.idxmax()} and {gender_by_race.idxmin()}\")\n",
    "    \n",
    "    # 3. RACE CLASSIFICATION ACCURACY BY GENDER\n",
    "    \n",
    "    if all(col in df_results.columns for col in ['race_correct', 'gender']):\n",
    "        race_by_gender = df_results.groupby('gender')['race_correct'].mean() * 100\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        bars = ax.bar(race_by_gender.index, race_by_gender.values)\n",
    "        \n",
    "        # Add labels and formatting\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_xlabel('Gender')\n",
    "        ax.set_ylabel('Race Classification Accuracy (%)')\n",
    "        ax.set_title('Race Classification Accuracy by Gender')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'race_accuracy_by_gender.png'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Print findings\n",
    "        print(\"\\nRace Classification Accuracy by Gender:\")\n",
    "        print(race_by_gender)\n",
    "        if len(race_by_gender) > 1:\n",
    "            print(f\"Disparity: {race_by_gender.max() - race_by_gender.min():.2f}% between {race_by_gender.idxmax()} and {race_by_gender.idxmin()}\")\n",
    "    \n",
    "    # 4. RACE CLASSIFICATION ACCURACY BY AGE\n",
    "    \n",
    "    if all(col in df_results.columns for col in ['race_correct', 'age']):\n",
    "        # Create age groups for better visualization\n",
    "        # df_results['age_group'] = pd.cut(\n",
    "        #     pd.to_numeric(df_results['age'], errors='coerce'),\n",
    "        #     bins=[0, 10, 20, 30, 40, 50, 60, 100],\n",
    "        #     labels=['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60+']\n",
    "        # )\n",
    "        \n",
    "        # Calculate accuracy by age group\n",
    "        race_by_age = df_results.groupby('age')['race_correct'].mean() * 100\n",
    "        age_order = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', 'more than 70']\n",
    "        race_by_age = race_by_age.reindex(age_order)\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        bars = ax.bar(race_by_age.index, race_by_age.values)\n",
    "        \n",
    "        # Add labels and formatting\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_xlabel('Age Group')\n",
    "        ax.set_ylabel('Race Classification Accuracy (%)')\n",
    "        ax.set_title('Race Classification Accuracy by Age Group')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'race_accuracy_by_age.png'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Print findings\n",
    "        print(\"\\nRace Classification Accuracy by Age Group:\")\n",
    "        print(race_by_age)\n",
    "        if not race_by_age.isna().all():\n",
    "            print(f\"Disparity: {race_by_age.max() - race_by_age.min():.2f}% between {race_by_age.idxmax()} and {race_by_age.idxmin()}\")\n",
    "    \n",
    "    # 5. GENDER CLASSIFICATION ACCURACY BY AGE\n",
    "    \n",
    "    if all(col in df_results.columns for col in ['gender_correct', 'age']):\n",
    "        gender_by_age = df_results.groupby('age')['gender_correct'].mean() * 100\n",
    "        age_order = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', 'more than 70']\n",
    "        gender_by_age = gender_by_age.reindex(age_order)   \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        bars = ax.bar(gender_by_age.index, gender_by_age.values)\n",
    "        \n",
    "        # Add labels and formatting\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_xlabel('Age Group')\n",
    "        ax.set_ylabel('Gender Classification Accuracy (%)')\n",
    "        ax.set_title('Gender Classification Accuracy by Age Group')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'gender_accuracy_by_age.png'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Print findings\n",
    "        print(\"\\nGender Classification Accuracy by Age Group:\")\n",
    "        print(gender_by_age)\n",
    "        if not gender_by_age.isna().all():\n",
    "            print(f\"Disparity: {gender_by_age.max() - gender_by_age.min():.2f}% between {gender_by_age.idxmax()} and {gender_by_age.idxmin()}\")\n",
    "    \n",
    "    \n",
    "    # Gender confusion matrix\n",
    "    if all(col in df_results.columns for col in ['gender', 'predicted_gender']):\n",
    "        # Filter out rows with missing predictions\n",
    "        df_gender = df_results.dropna(subset=['predicted_gender']).copy()\n",
    "        \n",
    "        if len(df_gender) > 0:\n",
    "            # Create confusion matrix\n",
    "            gender_cm = pd.crosstab(\n",
    "                df_gender['gender'], \n",
    "                df_gender['predicted_gender'],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(gender_cm, annot=True, fmt='.1f', cmap=\"viridis\", vmin=0, vmax=100)\n",
    "            plt.title('Gender Classification Confusion Matrix (% of actual)')\n",
    "            plt.ylabel('True Gender')\n",
    "            plt.xlabel('Predicted Gender')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'gender_confusion_matrix.png'), dpi=300)\n",
    "            plt.close()\n",
    "    \n",
    "    # Race confusion matrix\n",
    "    if all(col in df_results.columns for col in ['race', 'predicted_race']):\n",
    "        # Filter out rows with missing predictions\n",
    "        df_race = df_results.dropna(subset=['predicted_race']).copy()\n",
    "        \n",
    "        if len(df_race) > 0:\n",
    "            # Create confusion matrix\n",
    "            race_cm = pd.crosstab(\n",
    "                df_race['race'], \n",
    "                df_race['predicted_race'],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            \n",
    "            plt.figure(figsize=(14, 12))\n",
    "            sns.heatmap(race_cm, annot=True, fmt='.1f', cmap=\"viridis\", vmin=0, vmax=100)\n",
    "            plt.title('Race Classification Confusion Matrix (% of actual)')\n",
    "            plt.ylabel('True Race')\n",
    "            plt.xlabel('Predicted Race')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'race_confusion_matrix.png'), dpi=300)\n",
    "            plt.close()\n",
    "    \n",
    "    # 9. INTERSECTIONAL ANALYSIS: GENDER_RACE HEATMAP\n",
    "    \n",
    "    if all(col in df_results.columns for col in ['gender_correct', 'race_correct', 'gender_race']):\n",
    "        # Create a pivot table for heatmap visualization\n",
    "        gender_race_accuracy = df_results.pivot_table(\n",
    "            index='gender', \n",
    "            columns='race',\n",
    "            values=['gender_correct', 'race_correct'],\n",
    "            aggfunc='mean'\n",
    "        ) * 100\n",
    "        \n",
    "        # Gender accuracy heatmap\n",
    "        if ('gender_correct' in gender_race_accuracy.columns.levels[0]) and (not gender_race_accuracy['gender_correct'].isna().all().all()):\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            sns.heatmap(\n",
    "                gender_race_accuracy['gender_correct'], \n",
    "                annot=True, \n",
    "                fmt='.1f', \n",
    "                cmap=\"viridis\",\n",
    "                vmin=0,\n",
    "                vmax=100,\n",
    "                cbar_kws={'label': 'Accuracy (%)'}\n",
    "            )\n",
    "            plt.title('Gender Classification Accuracy by Gender and Race')\n",
    "            plt.ylabel('Gender')\n",
    "            plt.xlabel('Race')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'gender_race_heatmap.png'), dpi=300)\n",
    "            plt.close()\n",
    "        \n",
    "        # Race accuracy heatmap\n",
    "        if ('race_correct' in gender_race_accuracy.columns.levels[0]) and (not gender_race_accuracy['race_correct'].isna().all().all()):\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            sns.heatmap(\n",
    "                gender_race_accuracy['race_correct'], \n",
    "                annot=True, \n",
    "                fmt='.1f', \n",
    "                cmap=\"viridis\",\n",
    "                vmin=0,\n",
    "                vmax=100,\n",
    "                cbar_kws={'label': 'Accuracy (%)'}\n",
    "            )\n",
    "            plt.title('Race Classification Accuracy by Gender and Race')\n",
    "            plt.ylabel('Gender')\n",
    "            plt.xlabel('Race')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'race_gender_heatmap.png'), dpi=300)\n",
    "            plt.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f\"\\nAll visualizations saved to {output_dir}/\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9914dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_opencv_results(results_df):\n",
    "    \"\"\"\n",
    "    Analyze OpenCV Haar Cascades results.\n",
    "    Args:\n",
    "        results_df: DataFrame with detection results\n",
    "    \"\"\"\n",
    "    print(\"\\n--- OpenCV Haar Cascades Analysis ---\")\n",
    "    \n",
    "    # Detection rate by race\n",
    "    detection_by_race = results_df.groupby('race')['detected'].mean()\n",
    "    print(\"\\nDetection Rate by Race:\")\n",
    "    print(detection_by_race)\n",
    "    \n",
    "    # Average confidence by race (for detected faces)\n",
    "    confidence_by_race = results_df[results_df['detected']].groupby('race')['confidence'].mean()\n",
    "    print(\"\\nAverage Confidence by Race (for detected faces):\")\n",
    "    print(confidence_by_race)\n",
    "    \n",
    "    # Plot detection rate by race\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=detection_by_race.index, y=detection_by_race.values)\n",
    "    plt.title('Face Detection Rate by Race (OpenCV Haar Cascades)')\n",
    "    plt.xlabel('Race')\n",
    "    plt.ylabel('Detection Rate')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"finalfinalresults\", 'opencv_detection_rate.png'))\n",
    "    \n",
    "    # Plot confidence by race\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=confidence_by_race.index, y=confidence_by_race.values)\n",
    "    plt.title('Average Confidence by Race (OpenCV Haar Cascades)')\n",
    "    plt.xlabel('Race')\n",
    "    plt.ylabel('Confidence Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"finalfinalresults\", 'opencv_confidence.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in CSV file: ['file', 'age', 'gender', 'race', 'service_test']\n",
      "Total records in CSV: 86744\n",
      "Created 'gender_race' column by combining 'gender' and 'race'\n",
      "Sampled 500 records\n",
      "Checking image paths in directory: C:\\Users\\jonat\\Desktop\\dataethicsproj\\data259-project\\analysis\\data\\fairface-img-margin025-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking image files: 100%|██████████| 500/500 [00:00<00:00, 2099.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 images with valid file paths out of 500 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
      "Testing DeepFace:   0%|          | 1/500 [00:01<15:07,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFace analysis structure for train/47414.jpg:\n",
      "<class 'dict'>\n",
      "dict_keys(['age', 'region', 'face_confidence', 'gender', 'dominant_gender', 'race', 'dominant_race'])\n",
      "  age: <class 'int'> - 30\n",
      "  region: <class 'dict'> - {'x': 0, 'y': 0, 'w': 223, 'h': 223, 'left_eye': (141, 58), 'right_eye': (83, 63)}\n",
      "  face_confidence: <class 'numpy.float64'> - 0.93\n",
      "  gender: <class 'dict'> - {'Woman': 1.7560571432113647, 'Man': 98.2439398765564}\n",
      "  dominant_gender: <class 'str'> - Man\n",
      "  race: <class 'dict'> - {'asian': 0.09687183764725478, 'indian': 1.859305275595817, 'black': 0.07329193468333002, 'white': 54.116303219354535, 'middle eastern': 33.00789392088579, 'latino hispanic': 10.846338969032642}\n",
      "  dominant_race: <class 'str'> - white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.60it/s]\n",
      "Testing DeepFace:   0%|          | 2/500 [00:02<10:36,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFace analysis structure for train/52264.jpg:\n",
      "<class 'dict'>\n",
      "dict_keys(['age', 'region', 'face_confidence', 'gender', 'dominant_gender', 'race', 'dominant_race'])\n",
      "  age: <class 'int'> - 30\n",
      "  region: <class 'dict'> - {'x': 0, 'y': 0, 'w': 223, 'h': 223, 'left_eye': (148, 68), 'right_eye': (69, 70)}\n",
      "  face_confidence: <class 'numpy.float64'> - 0.93\n",
      "  gender: <class 'dict'> - {'Woman': 5.082449092697061e-05, 'Man': 99.99995231628418}\n",
      "  dominant_gender: <class 'str'> - Man\n",
      "  race: <class 'dict'> - {'asian': 0.11518732644617558, 'indian': 4.047111049294472, 'black': 0.23568044416606426, 'white': 25.98211169242859, 'middle eastern': 59.918588399887085, 'latino hispanic': 9.701324999332428}\n",
      "  dominant_race: <class 'str'> - middle eastern\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.66it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.78it/s]0s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.97it/s]0it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]9it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  4.08it/s]2it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  4.24it/s]6it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]1it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  4.05it/s]1it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.99it/s]22it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]23it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.49it/s]21it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]16it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.85it/s]15it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.75it/s]17it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.77it/s]17it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.64it/s]17it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  4.03it/s]16it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]19it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  4.04it/s]20it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.96it/s]21it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.83it/s]21it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]21it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]08it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.29it/s]13s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.63it/s]24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.75it/s]24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.89it/s]22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.82it/s]19s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.66it/s]09s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.63it/s]02s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.34it/s]02it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.48it/s]03it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.53it/s]06it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]08it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.99it/s]12it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.84it/s]15it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.82it/s]17it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  4.02it/s]18it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s]21it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.14it/s]07it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s]11s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]33s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.15it/s]44s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]44s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]54s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]69s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]75s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]81s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.05it/s]82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]73s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]74s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.28it/s]77s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]66s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.50it/s]65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s]52s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s]43s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.35it/s]37s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.55it/s]36s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.82it/s]33s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.59it/s]28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s]26s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.63it/s]25s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s]23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.90it/s]24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.78it/s]19s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.63it/s]17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.77it/s]18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.79it/s]18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.81it/s]18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.87it/s]17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s]15s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.55it/s]18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s]19s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s]21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.65it/s]20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s]21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]30s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]39s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]45s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.07it/s]51s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]53s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]58s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]63s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]66s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]66s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]64s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]61s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]61s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.92it/s]62s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s].65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s].65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s].65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s].65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s].68s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s].69s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s].68s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s].69s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.96it/s].72s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s].71s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s].67s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s].69s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.96it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s].67s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s].71s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s].74s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s].77s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s].75s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s].72s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s].73s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s].75s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s].77s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s].85s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s].85s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.67it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s].89s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s].88s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s].86s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s].86s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s].88s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].89s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s].89s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:02<00:00,  1.37it/s].89s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s].01s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s].27s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].12s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s].06s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s].97s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s].96s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.34it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s].54s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s].52s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:03<00:00,  1.30s/it].54s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s].28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s].13s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.98it/s].02s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s].85s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s].81s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s].77s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s].71s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.98it/s].71s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.14it/s].68s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s].64s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].62s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.59it/s].78s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s].85s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:02<00:00,  1.49it/s].94s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].04s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s].02s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s].86s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s].81s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].81s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.03it/s].91s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.74it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.53it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.58it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s].94s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.67it/s].89s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s].89s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s].85s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].94s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s].94s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s].94s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.05it/s].91s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s].83s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s].79s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.12it/s].80s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s].73s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s].73s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s].73s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.03it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.13it/s].65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s].60s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s].50s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.68it/s].41s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.75it/s].34s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.13it/s].30s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s].35s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.58it/s].58s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s].73s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s].83s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].88s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].91s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].95s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s].96s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].03s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s].00s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].98s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.67it/s].96s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s].95s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].91s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s].93s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s].93s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].91s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s].96s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].95s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:02<00:00,  1.49it/s].95s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].00s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.67it/s].97s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s].95s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s].96s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s].93s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s].01s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s].97s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s].00s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s].00s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s].01s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].01s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s].00s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s].99s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s].89s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.62it/s].86s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s].90s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s].93s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s].94s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s].91s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s].82s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s].80s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s].92s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.96it/s].87s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.05it/s].79s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.97it/s].74s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.45it/s].56s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.13it/s].49s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s].49s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.98it/s].54s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s].57s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s].62s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s].71s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s].77s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.56it/s].69s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s].58s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s].60s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.96it/s].64s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s].65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s].69s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s].67s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.26it/s].74s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.14it/s].65s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.22it/s].60s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s].55s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s].55s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s].64s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s].66s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s].67s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s].73s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.67it/s].70s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.07it/s].75s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.64it/s].71s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.35it/s].57s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.01it/s].51s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.30it/s].41s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.91it/s].27s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.86it/s].26s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s].24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.23it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.09it/s].28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.28it/s].35s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.38it/s].39s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.29it/s].37s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s].38s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.49it/s].40s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s].36s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.80it/s].30s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.85it/s].27s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.82it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.26it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.20it/s].15s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.26it/s].10s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.82it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.18it/s].10s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.02it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s].06s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.46it/s].09s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.84it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.10it/s].13s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.20it/s].13s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.99it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.92it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.10it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.20it/s].06s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.45it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.14it/s].02s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.26it/s].04s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.07it/s].04s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.95it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.84it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.88it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.44it/s].09s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.66it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.64it/s].10s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.52it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.59it/s].18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.78it/s].20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.57it/s].19s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.29it/s].20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.54it/s].27s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s].26s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.51it/s].25s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s].25s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.14it/s].28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.29it/s].33s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s].35s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.78it/s].30s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.83it/s].25s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.68it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.67it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.59it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.67it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.72it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.55it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.36it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.56it/s].28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.48it/s].28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.41it/s].29s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.82it/s].30s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.11it/s].24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.49it/s].17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.76it/s].20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.34it/s].19s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s].24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.15it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s].16s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.54it/s].18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.48it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.02it/s].24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.97it/s].20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.84it/s].16s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.95it/s].16s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.39it/s].13s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.59it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.81it/s].24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.01it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.05it/s].17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.83it/s].13s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.22it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.55it/s].11s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.05it/s].15s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.77it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.47it/s].15s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.52it/s].20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.68it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.63it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.47it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.49it/s].25s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s].26s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.66it/s].25s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.36it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.30it/s].28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.21it/s].32s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.07it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.35it/s].18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.21it/s].11s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.20it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.43it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.10it/s].03s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.77it/s].04s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.06it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.36it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.35it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.31it/s].02s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.76it/s].01s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.00it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.11it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.32it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.96it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.09it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.34it/s].06s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.52it/s].03s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.26it/s].01s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.44it/s].01s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.40it/s].01it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.91it/s].03it/s]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.76it/s].02s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.10it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.41it/s].04s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.78it/s].12s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.76it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.65it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.52it/s].15s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.47it/s].18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.54it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.75it/s].23s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.97it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.93it/s].18s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.91it/s].16s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.86it/s].15s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.40it/s].15s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s].20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.99it/s].21s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.15it/s].17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.17it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.03it/s].11s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.89it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.03it/s].09s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.68it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.15it/s].12s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.26it/s].24s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.44it/s].30s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.72it/s].30s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s].28s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s].42s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.39it/s].53s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.40it/s].48s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s].45s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s].84s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s].83s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s].83s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.03it/s].81s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.98it/s].59s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.95it/s].43s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.81it/s].32s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.03it/s].26s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.84it/s].22s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.88it/s].20s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.11it/s].17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.07it/s].12s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.23it/s].09s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.16it/s].06s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.99it/s].04s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.95it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.93it/s].05s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.88it/s].06s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.93it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.12it/s].08s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.79it/s].07s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.54it/s].10s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.82it/s].17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s].16s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.04it/s].17s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.02it/s].14s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.04it/s].12s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.01it/s].10s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:00<00:00,  3.06it/s].10s/it]\n",
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.91it/s].10s/it]\n",
      "Testing DeepFace: 100%|██████████| 500/500 [12:13<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFace results shape: (500, 11), columns: ['file', 'gender', 'race', 'age', 'gender_race', 'detected', 'predicted_gender', 'predicted_race', 'predicted_age', 'gender_correct', 'race_correct']\n",
      "Analyzing OpenCV Haar Cascades...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image_path'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fairface_df \u001b[38;5;241m=\u001b[39m load_fairface_data(FAIRFACE_CSV, FAIRFACE_DIR, \u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      2\u001b[0m deepface_results \u001b[38;5;241m=\u001b[39m test_deepface(fairface_df, FAIRFACE_DIR)\n\u001b[1;32m----> 3\u001b[0m opencv_results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_opencv_haar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfairface_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(deepface_results)\n",
      "Cell \u001b[1;32mIn [41], line 22\u001b[0m, in \u001b[0;36manalyze_opencv_haar\u001b[1;34m(data_df, sample_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m tqdm(data_df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_df)):\n\u001b[1;32m---> 22\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m     race \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m# Read image\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image_path'"
     ]
    }
   ],
   "source": [
    "fairface_df = load_fairface_data(FAIRFACE_CSV, FAIRFACE_DIR, 500)\n",
    "deepface_results = test_deepface(fairface_df, FAIRFACE_DIR)\n",
    "opencv_results = analyze_opencv_haar(fairface_df)\n",
    "analyze_opencv_results(opencv_results)\n",
    "print(deepface_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a1902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender Classification Accuracy by Race:\n",
      "race\n",
      "Southeast Asian    65.517241\n",
      "White              65.591398\n",
      "Black              65.789474\n",
      "Indian             70.491803\n",
      "East Asian         70.666667\n",
      "Latino_Hispanic    71.052632\n",
      "Middle Eastern     83.606557\n",
      "Name: gender_correct, dtype: float64\n",
      "Disparity: 18.09% between Middle Eastern and Southeast Asian\n",
      "\n",
      "Race Classification Accuracy by Gender:\n",
      "gender\n",
      "Female    59.459459\n",
      "Male      61.870504\n",
      "Name: race_correct, dtype: float64\n",
      "Disparity: 2.41% between Male and Female\n",
      "\n",
      "Race Classification Accuracy by Age Group:\n",
      "age\n",
      "0-2             71.428571\n",
      "3-9             70.491803\n",
      "10-19           48.437500\n",
      "20-29           62.264151\n",
      "30-39           63.888889\n",
      "40-49           56.000000\n",
      "50-59           47.058824\n",
      "60-69           83.333333\n",
      "more than 70    60.000000\n",
      "Name: race_correct, dtype: float64\n",
      "Disparity: 36.27% between 60-69 and 50-59\n",
      "\n",
      "Gender Classification Accuracy by Age Group:\n",
      "age\n",
      "0-2             85.714286\n",
      "3-9             70.491803\n",
      "10-19           56.250000\n",
      "20-29           68.553459\n",
      "30-39           75.925926\n",
      "40-49           74.000000\n",
      "50-59           73.529412\n",
      "60-69           83.333333\n",
      "more than 70    40.000000\n",
      "Name: gender_correct, dtype: float64\n",
      "Disparity: 45.71% between 0-2 and more than 70\n",
      "\n",
      "All visualizations saved to finalfinalresults/\n"
     ]
    }
   ],
   "source": [
    "create_comprehensive_visualizations(deepface_results, output_dir='finalfinalresults')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a364a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comprehensive_disparate_impact(df_results, output_dir='finalfinalresults'):\n",
    "    \"\"\"\n",
    "    Calculate disparate impact across all demographic attribute combinations\n",
    "    \n",
    "    Args:\n",
    "        df_results: DataFrame with results (must contain predicted_gender, gender, \n",
    "                   predicted_race, race, age columns and their correctness indicators)\n",
    "        output_dir: Directory to save visualizations\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing calculated disparate impact metrics\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set up plotting style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    sns.set_palette(\"viridis\")\n",
    "    \n",
    "    # Store all metrics in dictionary\n",
    "    disparate_impact_metrics = {\n",
    "        'gender_classification': {},\n",
    "        'race_classification': {}\n",
    "    }\n",
    "    \n",
    "    # Define demographic attributes to analyze\n",
    "    demographic_attrs = []\n",
    "    if 'race' in df_results.columns:\n",
    "        demographic_attrs.append('race')\n",
    "    if 'gender' in df_results.columns:\n",
    "        demographic_attrs.append('gender')\n",
    "    if 'age' in df_results.columns:\n",
    "        demographic_attrs.append('age')\n",
    "    \n",
    "    # Define standardized age order if needed\n",
    "    age_order = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', 'more than 70']\n",
    "    \n",
    "    print(\"\\n=== COMPREHENSIVE DISPARATE IMPACT ANALYSIS ===\")\n",
    "    \n",
    "    # Function to calculate and visualize disparate impact for a specific task and attribute\n",
    "    def analyze_disparate_impact(task, attribute):\n",
    "        print(f\"\\n--- {task.capitalize()} Classification by {attribute.capitalize()} ---\")\n",
    "        \n",
    "        # Determine the correctness column\n",
    "        correct_col = f\"{task}_correct\"\n",
    "        if correct_col not in df_results.columns:\n",
    "            print(f\"Error: {correct_col} column not found\")\n",
    "            return None\n",
    "        \n",
    "        # Get unique attribute values\n",
    "        attr_values = sorted(df_results[attribute].unique())\n",
    "        if attribute == 'age' and all(age in age_order for age in attr_values):\n",
    "            # Sort age groups using predefined order\n",
    "            sorterIndex = dict(zip(age_order, range(len(age_order))))\n",
    "            attr_values = sorted(attr_values, key=lambda x: sorterIndex.get(x, 999))\n",
    "        \n",
    "        # Calculate overall accuracy as baseline\n",
    "        overall_accuracy = df_results[correct_col].mean()\n",
    "        print(f\"Overall {task} classification accuracy: {overall_accuracy:.4f}\")\n",
    "        \n",
    "        # Dictionary to store results\n",
    "        accuracy_by_attr = {}\n",
    "        \n",
    "        for value in attr_values:\n",
    "            # Filter data for this attribute value\n",
    "            attr_mask = (df_results[attribute] == value)\n",
    "            df_filtered = df_results[attr_mask].copy()\n",
    "            \n",
    "            # Skip if not enough data\n",
    "            if len(df_filtered) < 10:\n",
    "                print(f\"Skipping {attribute}={value}: insufficient data (n={len(df_filtered)})\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate accuracy for this attribute value\n",
    "            accuracy = df_filtered[correct_col].mean()\n",
    "            accuracy_by_attr[value] = accuracy\n",
    "            \n",
    "            # Calculate and print disparate impact ratio\n",
    "            di_ratio = accuracy / overall_accuracy\n",
    "            di_threshold = 0.8  # 80% rule\n",
    "            di_status = \"PASS\" if di_ratio >= di_threshold else \"FAIL\"\n",
    "            print(f\"{task.capitalize()} classification for {attribute}={value}: Accuracy = {accuracy:.4f}, DI Ratio = {di_ratio:.4f} ({di_status})\")\n",
    "        \n",
    "        # If we have results, create visualization\n",
    "        if accuracy_by_attr:\n",
    "            # Determine figure size based on number of attribute values\n",
    "            fig_width = max(10, len(accuracy_by_attr) * 1.0)\n",
    "            fig, ax = plt.subplots(figsize=(fig_width, 6))\n",
    "            \n",
    "            # Convert to DataFrame for easier plotting\n",
    "            di_df = pd.DataFrame({\n",
    "                attribute.capitalize(): list(accuracy_by_attr.keys()),\n",
    "                'Accuracy': list(accuracy_by_attr.values())\n",
    "            })\n",
    "            \n",
    "            # Plot bars\n",
    "            bars = ax.bar(di_df[attribute.capitalize()], di_df['Accuracy'])\n",
    "            \n",
    "            # Add horizontal line for 80% of max accuracy (disparate impact threshold)\n",
    "            max_accuracy = di_df['Accuracy'].max()\n",
    "            threshold = 0.8 * max_accuracy\n",
    "            ax.axhline(y=threshold, linestyle='--', color='r', \n",
    "                      label=f'80% Threshold ({threshold:.4f})')\n",
    "            \n",
    "            # Highlight bars below threshold\n",
    "            for i, (_, row) in enumerate(di_df.iterrows()):\n",
    "                if row['Accuracy'] < threshold:\n",
    "                    bars[i].set_color('red')\n",
    "            \n",
    "            # Add labels and formatting\n",
    "            ax.set_ylabel(f'{task.capitalize()} Classification Accuracy')\n",
    "            ax.set_title(f'Disparate Impact Analysis: {task.capitalize()} Classification by {attribute.capitalize()}')\n",
    "            ax.set_ylim(0, 1.0)\n",
    "            \n",
    "            # Add value labels on top of bars\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                        f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "            \n",
    "            # Adjust x-axis formatting based on attribute\n",
    "            if len(attr_values) > 5 or any(len(str(val)) > 10 for val in attr_values):\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'{task}_disparate_impact_by_{attribute}.png'), dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            # Store metrics\n",
    "            disparate_impact_metrics[f'{task}_classification'][f'disparate_impact_by_{attribute}'] = {\n",
    "                f'{attribute}_accuracies': accuracy_by_attr,\n",
    "                'overall_accuracy': overall_accuracy,\n",
    "                'threshold': threshold,\n",
    "                'di_ratios': {val: acc/overall_accuracy for val, acc in accuracy_by_attr.items()},\n",
    "                'failing_groups': [val for val, acc in accuracy_by_attr.items() if acc < threshold]\n",
    "            }\n",
    "            \n",
    "            return accuracy_by_attr\n",
    "        return None\n",
    "\n",
    "    # Function to calculate and visualize disparate impact for intersectional attributes\n",
    "    def analyze_intersectional_disparate_impact(task, attr1, attr2):\n",
    "        print(f\"\\n--- {task.capitalize()} Classification by {attr1.capitalize()} and {attr2.capitalize()} ---\")\n",
    "        \n",
    "        # Determine the correctness column\n",
    "        correct_col = f\"{task}_correct\"\n",
    "        if correct_col not in df_results.columns:\n",
    "            print(f\"Error: {correct_col} column not found\")\n",
    "            return None\n",
    "        \n",
    "        # Get unique attribute values\n",
    "        attr1_values = sorted(df_results[attr1].unique())\n",
    "        attr2_values = sorted(df_results[attr2].unique())\n",
    "        \n",
    "        # Sort age groups if applicable\n",
    "        if attr1 == 'age' and all(age in age_order for age in attr1_values):\n",
    "            sorterIndex = dict(zip(age_order, range(len(age_order))))\n",
    "            attr1_values = sorted(attr1_values, key=lambda x: sorterIndex.get(x, 999))\n",
    "        if attr2 == 'age' and all(age in age_order for age in attr2_values):\n",
    "            sorterIndex = dict(zip(age_order, range(len(age_order))))\n",
    "            attr2_values = sorted(attr2_values, key=lambda x: sorterIndex.get(x, 999))\n",
    "        \n",
    "        # Calculate overall accuracy as baseline\n",
    "        overall_accuracy = df_results[correct_col].mean()\n",
    "        \n",
    "        # Prepare heatmap data\n",
    "        heatmap_data = []\n",
    "        \n",
    "        for val1 in attr1_values:\n",
    "            for val2 in attr2_values:\n",
    "                # Filter for this combination\n",
    "                mask = (df_results[attr1] == val1) & (df_results[attr2] == val2)\n",
    "                df_subset = df_results[mask].copy()\n",
    "                \n",
    "                # Only include if we have enough data\n",
    "                if len(df_subset) >= 10:\n",
    "                    accuracy = df_subset[correct_col].mean()\n",
    "                    di_ratio = accuracy / overall_accuracy\n",
    "                    \n",
    "                    heatmap_data.append({\n",
    "                        attr1: val1,\n",
    "                        attr2: val2,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'DI_Ratio': di_ratio,\n",
    "                        'Sample_Size': len(df_subset)\n",
    "                    })\n",
    "        \n",
    "        # Only create visualization if we have enough data\n",
    "        if len(heatmap_data) > 3:\n",
    "            heatmap_df = pd.DataFrame(heatmap_data)\n",
    "            \n",
    "            # Create pivot tables for heatmaps\n",
    "            pivot_acc = heatmap_df.pivot_table(\n",
    "                index=attr1, \n",
    "                columns=attr2,\n",
    "                values='Accuracy'\n",
    "            )\n",
    "            \n",
    "            pivot_di = heatmap_df.pivot_table(\n",
    "                index=attr1, \n",
    "                columns=attr2,\n",
    "                values='DI_Ratio'\n",
    "            )\n",
    "            \n",
    "            pivot_size = heatmap_df.pivot_table(\n",
    "                index=attr1, \n",
    "                columns=attr2,\n",
    "                values='Sample_Size'\n",
    "            )\n",
    "            \n",
    "            # Create heatmap for accuracy\n",
    "            plt.figure(figsize=(max(8, len(attr2_values) * 1.2), max(6, len(attr1_values) * 0.8)))\n",
    "            ax = sns.heatmap(\n",
    "                pivot_acc, \n",
    "                annot=True, \n",
    "                fmt='.3f', \n",
    "                cmap='viridis',\n",
    "                vmin=max(0.5, pivot_acc.values.min() - 0.05),\n",
    "                vmax=min(1.0, pivot_acc.values.max() + 0.05),\n",
    "                cbar_kws={'label': 'Accuracy'}\n",
    "            )\n",
    "            \n",
    "            plt.title(f'Intersectional Analysis: {task.capitalize()} Classification Accuracy by {attr1.capitalize()} and {attr2.capitalize()}')\n",
    "            plt.ylabel(attr1.capitalize())\n",
    "            plt.xlabel(attr2.capitalize())\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'{task}_accuracy_{attr1}_{attr2}_heatmap.png'), dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            # Create heatmap for disparate impact ratio\n",
    "            plt.figure(figsize=(max(8, len(attr2_values) * 1.2), max(6, len(attr1_values) * 0.8)))\n",
    "            ax = sns.heatmap(\n",
    "                pivot_di, \n",
    "                annot=True, \n",
    "                fmt='.3f', \n",
    "                cmap='RdYlGn',\n",
    "                vmin=0.7,  # Below 0.8 is problematic\n",
    "                vmax=1.3,\n",
    "                cbar_kws={'label': 'Disparate Impact Ratio'}\n",
    "            )\n",
    "            \n",
    "            # Add reference lines\n",
    "            ax.axhline(y=0, color='black', linewidth=1)\n",
    "            ax.axvline(x=0, color='black', linewidth=1)\n",
    "            \n",
    "            plt.title(f'Intersectional Analysis: {task.capitalize()} Classification Disparate Impact by {attr1.capitalize()} and {attr2.capitalize()}')\n",
    "            plt.ylabel(attr1.capitalize())\n",
    "            plt.xlabel(attr2.capitalize())\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'{task}_disparate_impact_{attr1}_{attr2}_heatmap.png'), dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            # Store metrics\n",
    "            disparate_impact_metrics[f'{task}_classification'][f'disparate_impact_{attr1}_{attr2}'] = {\n",
    "                'data': heatmap_data,\n",
    "                'overall_accuracy': overall_accuracy,\n",
    "                'failing_combinations': [\n",
    "                    {attr1: row[attr1], attr2: row[attr2], 'accuracy': row['Accuracy'], 'di_ratio': row['DI_Ratio']}\n",
    "                    for _, row in heatmap_df.iterrows() if row['DI_Ratio'] < 0.8\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            return heatmap_data\n",
    "        else:\n",
    "            print(f\"Not enough data for meaningful intersectional analysis of {attr1} and {attr2}\")\n",
    "            return None\n",
    "    \n",
    "    # Tasks we'll analyze\n",
    "    tasks = []\n",
    "    if 'gender_correct' in df_results.columns:\n",
    "        tasks.append('gender')\n",
    "    if 'race_correct' in df_results.columns:\n",
    "        tasks.append('race')\n",
    "    \n",
    "    # 1. Calculate basic disparate impact for each task and demographic attribute\n",
    "    for task in tasks:\n",
    "        for attribute in demographic_attrs:\n",
    "            # Skip self-comparisons (e.g., race classification by race)\n",
    "            if not (task == attribute):\n",
    "                analyze_disparate_impact(task, attribute)\n",
    "    \n",
    "    # 2. Calculate intersectional disparate impact for combinations of demographic attributes\n",
    "    for task in tasks:\n",
    "        # Get all pairs of demographic attributes\n",
    "        for i, attr1 in enumerate(demographic_attrs):\n",
    "            for attr2 in demographic_attrs[i+1:]:\n",
    "                # Skip any combinations involving the task itself\n",
    "                if task != attr1 and task != attr2:\n",
    "                    analyze_intersectional_disparate_impact(task, attr1, attr2)\n",
    "    \n",
    "    # 3. Print summary of disparate impact findings\n",
    "    print(\"\\n=== DISPARATE IMPACT SUMMARY ===\")\n",
    "    for task in tasks:\n",
    "        print(f\"\\n{task.capitalize()} Classification:\")\n",
    "        \n",
    "        # Get all disparate impact metrics for this task\n",
    "        task_metrics = disparate_impact_metrics[f'{task}_classification']\n",
    "        \n",
    "        # Print failures for each demographic attribute\n",
    "        for metric_name, metric_data in task_metrics.items():\n",
    "            if 'failing_groups' in metric_data and metric_data['failing_groups']:\n",
    "                print(f\"  {metric_name}: {len(metric_data['failing_groups'])} failing groups\")\n",
    "                for group in metric_data['failing_groups']:\n",
    "                    ratio = metric_data['di_ratios'].get(group, 'N/A')\n",
    "                    print(f\"    - {group}: Ratio = {ratio:.4f}\")\n",
    "            elif 'failing_combinations' in metric_data and metric_data['failing_combinations']:\n",
    "                print(f\"  {metric_name}: {len(metric_data['failing_combinations'])} failing combinations\")\n",
    "                for combo in metric_data['failing_combinations'][:5]:  # Show at most 5 examples\n",
    "                    attrs = ', '.join([f\"{k}={v}\" for k, v in combo.items() if k not in ['accuracy', 'di_ratio']])\n",
    "                    print(f\"    - {attrs}: Ratio = {combo['di_ratio']:.4f}\")\n",
    "                if len(metric_data['failing_combinations']) > 5:\n",
    "                    print(f\"    - ... and {len(metric_data['failing_combinations']) - 5} more\")\n",
    "    \n",
    "    return disparate_impact_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6bb35957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPREHENSIVE DISPARATE IMPACT ANALYSIS ===\n",
      "\n",
      "--- Gender Classification by Race ---\n",
      "Overall gender classification accuracy: 0.7000\n",
      "Gender classification for race=Black: Accuracy = 0.6579, DI Ratio = 0.9398 (PASS)\n",
      "Gender classification for race=East Asian: Accuracy = 0.7067, DI Ratio = 1.0095 (PASS)\n",
      "Gender classification for race=Indian: Accuracy = 0.7049, DI Ratio = 1.0070 (PASS)\n",
      "Gender classification for race=Latino_Hispanic: Accuracy = 0.7105, DI Ratio = 1.0150 (PASS)\n",
      "Gender classification for race=Middle Eastern: Accuracy = 0.8361, DI Ratio = 1.1944 (PASS)\n",
      "Gender classification for race=Southeast Asian: Accuracy = 0.6552, DI Ratio = 0.9360 (PASS)\n",
      "Gender classification for race=White: Accuracy = 0.6559, DI Ratio = 0.9370 (PASS)\n",
      "\n",
      "--- Gender Classification by Age ---\n",
      "Overall gender classification accuracy: 0.7000\n",
      "Skipping age=0-2: insufficient data (n=7)\n",
      "Gender classification for age=3-9: Accuracy = 0.7049, DI Ratio = 1.0070 (PASS)\n",
      "Gender classification for age=10-19: Accuracy = 0.5625, DI Ratio = 0.8036 (PASS)\n",
      "Gender classification for age=20-29: Accuracy = 0.6855, DI Ratio = 0.9793 (PASS)\n",
      "Gender classification for age=30-39: Accuracy = 0.7593, DI Ratio = 1.0847 (PASS)\n",
      "Gender classification for age=40-49: Accuracy = 0.7400, DI Ratio = 1.0571 (PASS)\n",
      "Gender classification for age=50-59: Accuracy = 0.7353, DI Ratio = 1.0504 (PASS)\n",
      "Gender classification for age=60-69: Accuracy = 0.8333, DI Ratio = 1.1905 (PASS)\n",
      "Skipping age=more than 70: insufficient data (n=5)\n",
      "\n",
      "--- Race Classification by Gender ---\n",
      "Overall race classification accuracy: 0.6080\n",
      "Race classification for gender=Female: Accuracy = 0.5946, DI Ratio = 0.9780 (PASS)\n",
      "Race classification for gender=Male: Accuracy = 0.6187, DI Ratio = 1.0176 (PASS)\n",
      "\n",
      "--- Race Classification by Age ---\n",
      "Overall race classification accuracy: 0.6080\n",
      "Skipping age=0-2: insufficient data (n=7)\n",
      "Race classification for age=3-9: Accuracy = 0.7049, DI Ratio = 1.1594 (PASS)\n",
      "Race classification for age=10-19: Accuracy = 0.4844, DI Ratio = 0.7967 (FAIL)\n",
      "Race classification for age=20-29: Accuracy = 0.6226, DI Ratio = 1.0241 (PASS)\n",
      "Race classification for age=30-39: Accuracy = 0.6389, DI Ratio = 1.0508 (PASS)\n",
      "Race classification for age=40-49: Accuracy = 0.5600, DI Ratio = 0.9211 (PASS)\n",
      "Race classification for age=50-59: Accuracy = 0.4706, DI Ratio = 0.7740 (FAIL)\n",
      "Race classification for age=60-69: Accuracy = 0.8333, DI Ratio = 1.3706 (PASS)\n",
      "Skipping age=more than 70: insufficient data (n=5)\n",
      "\n",
      "--- Gender Classification by Race and Age ---\n",
      "\n",
      "--- Race Classification by Gender and Age ---\n",
      "\n",
      "=== DISPARATE IMPACT SUMMARY ===\n",
      "\n",
      "Gender Classification:\n",
      "  disparate_impact_by_race: 3 failing groups\n",
      "    - Black: Ratio = 0.9398\n",
      "    - Southeast Asian: Ratio = 0.9360\n",
      "    - White: Ratio = 0.9370\n",
      "  disparate_impact_by_age: 1 failing groups\n",
      "    - 10-19: Ratio = 0.8036\n",
      "  disparate_impact_race_age: 4 failing combinations\n",
      "    - race=Black, age=20-29: Ratio = 0.7563\n",
      "    - race=Latino_Hispanic, age=10-19: Ratio = 0.7692\n",
      "    - race=Southeast Asian, age=20-29: Ratio = 0.7143\n",
      "    - race=White, age=3-9: Ratio = 0.7143\n",
      "\n",
      "Race Classification:\n",
      "  disparate_impact_by_age: 5 failing groups\n",
      "    - 10-19: Ratio = 0.7967\n",
      "    - 20-29: Ratio = 1.0241\n",
      "    - 30-39: Ratio = 1.0508\n",
      "    - 40-49: Ratio = 0.9211\n",
      "    - 50-59: Ratio = 0.7740\n",
      "  disparate_impact_gender_age: 2 failing combinations\n",
      "    - gender=Female, age=50-59: Ratio = 0.6853\n",
      "    - gender=Male, age=10-19: Ratio = 0.7895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gender_classification': {'disparate_impact_by_race': {'race_accuracies': {'Black': 0.6578947368421053,\n",
       "    'East Asian': 0.7066666666666667,\n",
       "    'Indian': 0.7049180327868853,\n",
       "    'Latino_Hispanic': 0.7105263157894737,\n",
       "    'Middle Eastern': 0.8360655737704918,\n",
       "    'Southeast Asian': 0.6551724137931034,\n",
       "    'White': 0.6559139784946236},\n",
       "   'overall_accuracy': 0.7,\n",
       "   'threshold': 0.6688524590163936,\n",
       "   'di_ratios': {'Black': 0.9398496240601505,\n",
       "    'East Asian': 1.0095238095238095,\n",
       "    'Indian': 1.0070257611241218,\n",
       "    'Latino_Hispanic': 1.0150375939849625,\n",
       "    'Middle Eastern': 1.1943793911007028,\n",
       "    'Southeast Asian': 0.935960591133005,\n",
       "    'White': 0.9370199692780338},\n",
       "   'failing_groups': ['Black', 'Southeast Asian', 'White']},\n",
       "  'disparate_impact_by_age': {'age_accuracies': {'3-9': 0.7049180327868853,\n",
       "    '10-19': 0.5625,\n",
       "    '20-29': 0.6855345911949685,\n",
       "    '30-39': 0.7592592592592593,\n",
       "    '40-49': 0.74,\n",
       "    '50-59': 0.7352941176470589,\n",
       "    '60-69': 0.8333333333333334},\n",
       "   'overall_accuracy': 0.7,\n",
       "   'threshold': 0.6666666666666667,\n",
       "   'di_ratios': {'3-9': 1.0070257611241218,\n",
       "    '10-19': 0.8035714285714286,\n",
       "    '20-29': 0.9793351302785265,\n",
       "    '30-39': 1.0846560846560849,\n",
       "    '40-49': 1.0571428571428572,\n",
       "    '50-59': 1.050420168067227,\n",
       "    '60-69': 1.1904761904761907},\n",
       "   'failing_groups': ['10-19']},\n",
       "  'disparate_impact_race_age': {'data': [{'race': 'Black',\n",
       "     'age': '3-9',\n",
       "     'Accuracy': 0.7333333333333333,\n",
       "     'DI_Ratio': 1.0476190476190477,\n",
       "     'Sample_Size': 15},\n",
       "    {'race': 'Black',\n",
       "     'age': '10-19',\n",
       "     'Accuracy': 0.6,\n",
       "     'DI_Ratio': 0.8571428571428572,\n",
       "     'Sample_Size': 10},\n",
       "    {'race': 'Black',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.5294117647058824,\n",
       "     'DI_Ratio': 0.7563025210084034,\n",
       "     'Sample_Size': 17},\n",
       "    {'race': 'Black',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.75,\n",
       "     'DI_Ratio': 1.0714285714285714,\n",
       "     'Sample_Size': 16},\n",
       "    {'race': 'East Asian',\n",
       "     'age': '3-9',\n",
       "     'Accuracy': 0.8181818181818182,\n",
       "     'DI_Ratio': 1.168831168831169,\n",
       "     'Sample_Size': 11},\n",
       "    {'race': 'East Asian',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.6764705882352942,\n",
       "     'DI_Ratio': 0.9663865546218489,\n",
       "     'Sample_Size': 34},\n",
       "    {'race': 'East Asian',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.9090909090909091,\n",
       "     'DI_Ratio': 1.2987012987012987,\n",
       "     'Sample_Size': 11},\n",
       "    {'race': 'Indian',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.8,\n",
       "     'DI_Ratio': 1.142857142857143,\n",
       "     'Sample_Size': 20},\n",
       "    {'race': 'Indian',\n",
       "     'age': '40-49',\n",
       "     'Accuracy': 0.7,\n",
       "     'DI_Ratio': 1.0,\n",
       "     'Sample_Size': 10},\n",
       "    {'race': 'Latino_Hispanic',\n",
       "     'age': '10-19',\n",
       "     'Accuracy': 0.5384615384615384,\n",
       "     'DI_Ratio': 0.7692307692307693,\n",
       "     'Sample_Size': 13},\n",
       "    {'race': 'Latino_Hispanic',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.7916666666666666,\n",
       "     'DI_Ratio': 1.130952380952381,\n",
       "     'Sample_Size': 24},\n",
       "    {'race': 'Latino_Hispanic',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.6153846153846154,\n",
       "     'DI_Ratio': 0.8791208791208792,\n",
       "     'Sample_Size': 13},\n",
       "    {'race': 'Latino_Hispanic',\n",
       "     'age': '40-49',\n",
       "     'Accuracy': 0.7272727272727273,\n",
       "     'DI_Ratio': 1.038961038961039,\n",
       "     'Sample_Size': 11},\n",
       "    {'race': 'Middle Eastern',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.9230769230769231,\n",
       "     'DI_Ratio': 1.3186813186813189,\n",
       "     'Sample_Size': 13},\n",
       "    {'race': 'Middle Eastern',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.9047619047619048,\n",
       "     'DI_Ratio': 1.2925170068027212,\n",
       "     'Sample_Size': 21},\n",
       "    {'race': 'Southeast Asian',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.5,\n",
       "     'DI_Ratio': 0.7142857142857143,\n",
       "     'Sample_Size': 20},\n",
       "    {'race': 'Southeast Asian',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.8,\n",
       "     'DI_Ratio': 1.142857142857143,\n",
       "     'Sample_Size': 10},\n",
       "    {'race': 'White',\n",
       "     'age': '3-9',\n",
       "     'Accuracy': 0.5,\n",
       "     'DI_Ratio': 0.7142857142857143,\n",
       "     'Sample_Size': 10},\n",
       "    {'race': 'White',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.6451612903225806,\n",
       "     'DI_Ratio': 0.9216589861751152,\n",
       "     'Sample_Size': 31},\n",
       "    {'race': 'White',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.7,\n",
       "     'DI_Ratio': 1.0,\n",
       "     'Sample_Size': 30}],\n",
       "   'overall_accuracy': 0.7,\n",
       "   'failing_combinations': [{'race': 'Black',\n",
       "     'age': '20-29',\n",
       "     'accuracy': 0.5294117647058824,\n",
       "     'di_ratio': 0.7563025210084034},\n",
       "    {'race': 'Latino_Hispanic',\n",
       "     'age': '10-19',\n",
       "     'accuracy': 0.5384615384615384,\n",
       "     'di_ratio': 0.7692307692307693},\n",
       "    {'race': 'Southeast Asian',\n",
       "     'age': '20-29',\n",
       "     'accuracy': 0.5,\n",
       "     'di_ratio': 0.7142857142857143},\n",
       "    {'race': 'White',\n",
       "     'age': '3-9',\n",
       "     'accuracy': 0.5,\n",
       "     'di_ratio': 0.7142857142857143}]}},\n",
       " 'race_classification': {'disparate_impact_by_gender': {'gender_accuracies': {'Female': 0.5945945945945946,\n",
       "    'Male': 0.6187050359712231},\n",
       "   'overall_accuracy': 0.608,\n",
       "   'threshold': 0.4949640287769785,\n",
       "   'di_ratios': {'Female': 0.9779516358463728, 'Male': 1.0176069670579326},\n",
       "   'failing_groups': []},\n",
       "  'disparate_impact_by_age': {'age_accuracies': {'3-9': 0.7049180327868853,\n",
       "    '10-19': 0.484375,\n",
       "    '20-29': 0.6226415094339622,\n",
       "    '30-39': 0.6388888888888888,\n",
       "    '40-49': 0.56,\n",
       "    '50-59': 0.47058823529411764,\n",
       "    '60-69': 0.8333333333333334},\n",
       "   'overall_accuracy': 0.608,\n",
       "   'threshold': 0.6666666666666667,\n",
       "   'di_ratios': {'3-9': 1.159404659188956,\n",
       "    '10-19': 0.7966694078947368,\n",
       "    '20-29': 1.0240814299900696,\n",
       "    '30-39': 1.0508040935672514,\n",
       "    '40-49': 0.9210526315789475,\n",
       "    '50-59': 0.7739938080495357,\n",
       "    '60-69': 1.3706140350877194},\n",
       "   'failing_groups': ['10-19', '20-29', '30-39', '40-49', '50-59']},\n",
       "  'disparate_impact_gender_age': {'data': [{'gender': 'Female',\n",
       "     'age': '3-9',\n",
       "     'Accuracy': 0.5652173913043478,\n",
       "     'DI_Ratio': 0.9296338672768878,\n",
       "     'Sample_Size': 23},\n",
       "    {'gender': 'Female',\n",
       "     'age': '10-19',\n",
       "     'Accuracy': 0.48717948717948717,\n",
       "     'DI_Ratio': 0.8012820512820513,\n",
       "     'Sample_Size': 39},\n",
       "    {'gender': 'Female',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.6395348837209303,\n",
       "     'DI_Ratio': 1.0518665850673194,\n",
       "     'Sample_Size': 86},\n",
       "    {'gender': 'Female',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.6578947368421053,\n",
       "     'DI_Ratio': 1.0820637119113574,\n",
       "     'Sample_Size': 38},\n",
       "    {'gender': 'Female',\n",
       "     'age': '40-49',\n",
       "     'Accuracy': 0.6666666666666666,\n",
       "     'DI_Ratio': 1.0964912280701753,\n",
       "     'Sample_Size': 15},\n",
       "    {'gender': 'Female',\n",
       "     'age': '50-59',\n",
       "     'Accuracy': 0.4166666666666667,\n",
       "     'DI_Ratio': 0.6853070175438597,\n",
       "     'Sample_Size': 12},\n",
       "    {'gender': 'Male',\n",
       "     'age': '3-9',\n",
       "     'Accuracy': 0.7894736842105263,\n",
       "     'DI_Ratio': 1.298476454293629,\n",
       "     'Sample_Size': 38},\n",
       "    {'gender': 'Male',\n",
       "     'age': '10-19',\n",
       "     'Accuracy': 0.48,\n",
       "     'DI_Ratio': 0.7894736842105263,\n",
       "     'Sample_Size': 25},\n",
       "    {'gender': 'Male',\n",
       "     'age': '20-29',\n",
       "     'Accuracy': 0.6027397260273972,\n",
       "     'DI_Ratio': 0.9913482335976929,\n",
       "     'Sample_Size': 73},\n",
       "    {'gender': 'Male',\n",
       "     'age': '30-39',\n",
       "     'Accuracy': 0.6285714285714286,\n",
       "     'DI_Ratio': 1.0338345864661653,\n",
       "     'Sample_Size': 70},\n",
       "    {'gender': 'Male',\n",
       "     'age': '40-49',\n",
       "     'Accuracy': 0.5142857142857142,\n",
       "     'DI_Ratio': 0.8458646616541353,\n",
       "     'Sample_Size': 35},\n",
       "    {'gender': 'Male',\n",
       "     'age': '50-59',\n",
       "     'Accuracy': 0.5,\n",
       "     'DI_Ratio': 0.8223684210526316,\n",
       "     'Sample_Size': 22}],\n",
       "   'overall_accuracy': 0.608,\n",
       "   'failing_combinations': [{'gender': 'Female',\n",
       "     'age': '50-59',\n",
       "     'accuracy': 0.4166666666666667,\n",
       "     'di_ratio': 0.6853070175438597},\n",
       "    {'gender': 'Male',\n",
       "     'age': '10-19',\n",
       "     'accuracy': 0.48,\n",
       "     'di_ratio': 0.7894736842105263}]}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_comprehensive_disparate_impact(deepface_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
